name: Upload Marketing to GCS

on:
  workflow_dispatch:
  push:
    branches:
      - "**"
    paths:
      - '.github/workflows/upload-sql-to-gcs.yml'
      - 'test-git-hub-actions/marketing/**'

jobs:
  sync:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    env:
      PROJECT_ID: quick-platform-466015-d5
      # Make sure this bucket actually exists and the SA has access to it:
      BUCKET: gs://quick-platform-466015-d5/test-git-actions
      REPO_ROOT: test-git-hub-actions/marketing

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # Auth with a service account JSON stored in GitHub Secret GCP_SA_KEY
      - name: Auth & setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true

      - name: Verify gsutil & bucket
        shell: bash
        run: |
          set -euo pipefail
          gsutil --version
          # Validate the bucket base (everything before the first / after gs://)
          base="${BUCKET#gs://}"; base="gs://${base%%/*}"
          echo "Checking bucket base: $base"
          gsutil ls -b "$base" >/dev/null

      - name: Sync DAGs and data to GCS
        shell: bash
        run: |
          set -Eeuo pipefail
          shopt -s nullglob

          echo "Using PROJECT_ID=${PROJECT_ID}"
          echo "Using BUCKET=${BUCKET}"
          echo "Using REPO_ROOT=${REPO_ROOT}"

          # Collect subrepos under REPO_ROOT
          subrepos=()
          for d in "$REPO_ROOT"/*; do
            [[ -d "$d" ]] || continue
            subrepos+=( "$(basename "$d")" )
          done
          echo "Found subrepos: ${subrepos[*]:-<none>}"

          # 1) Sync DAGs (mirror)
          for sub in "${subrepos[@]}"; do
            src="$REPO_ROOT/$sub/dags"
            dst="$BUCKET/dags/$REPO_ROOT/$sub/dags"
            if [[ -d "$src" ]]; then
              echo "Syncing DAGs: $src -> $dst"
              gsutil -m rsync -d -r "$src" "$dst"
            else
              echo "No DAGs in $REPO_ROOT/$sub â€” removing GCS dags path if present: $dst"
              gsutil -m rm -r "$dst" 2>/dev/null || true
            fi
          done

          # Remove stale subfolders in GCS DAGs not present in Git
          echo "Cleaning stale GCS DAGs under $BUCKET/dags/$REPO_ROOT ..."
          while IFS= read -r gcs_path; do
            [[ -n "$gcs_path" ]] || continue
            # example: gs://.../dags/test-git-hub-actions/marketing/<sub>/dags
            gcs_sub=$(echo "$gcs_path" | sed 's:/*$::' | awk -F/ '{print $(NF-1)}')
            keep=false
            for sub in "${subrepos[@]}"; do
              if [[ "$sub" == "$gcs_sub" ]]; then keep=true; break; fi
            done
            if [[ "$keep" == false ]]; then
              echo "Deleting stale DAGs path: $gcs_path"
              gsutil -m rm -r "$gcs_path" || true
            fi
          done < <(gsutil ls -d "$BUCKET/dags/$REPO_ROOT/"*"/dags" 2>/dev/null || true)

          # 2) Sync other folders (everything except DAGs)
          for sub in "${subrepos[@]}"; do
            for dir in "$REPO_ROOT/$sub"/*; do
              [[ -d "$dir" ]] || continue
              folder=$(basename "$dir")
              if [[ "$folder" != "dags" ]]; then
                dst="$BUCKET/data/$REPO_ROOT/$sub/$folder/"
